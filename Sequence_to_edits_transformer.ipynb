{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4987a224",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "\n",
    "### Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51dac92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b32f2f50",
   "metadata": {
    "hide_input": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.legacy.data import Field, TabularDataset, BucketIterator\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "from torchmetrics.functional import precision_recall,f1_score,accuracy\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from torch import Tensor\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cba2cf",
   "metadata": {},
   "source": [
    "### parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d545ea5",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64 #1,2,4,8,16,32,64,128,256,512,1028\n",
    "path = \"data_filter/\"\n",
    "# path = \"small_data/\" \n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8e4c24",
   "metadata": {},
   "source": [
    "### seed initializing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11c135d1",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "seed=1234\n",
    "\n",
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "torch.backends.cudnn.determininistic=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9905bc",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef1ee0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1\n",
    "\n",
    "tokens = Field(sequential=True,use_vocab=True,batch_first = True,lower=True,pad_token=\"<pad>\", init_token = '<sos>', eos_token = '<eos>')\n",
    "edits = Field(sequential=True,use_vocab=True,batch_first = True,lower=True,pad_token=\"<pad>\", init_token = '<sos>', eos_token = '<eos>')\n",
    "\n",
    "fields = {'tokens':('tokens',tokens),'labels':('edits',edits)}\n",
    "\n",
    "train_data, val_data, test_data = TabularDataset.splits(path=path,train='ptrain.jsonl',validation='val.jsonl',\n",
    "                                                        test='test.jsonl',format='json',fields=fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70b1ac6d",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# step 2  Build a vocab\n",
    "tokens.build_vocab(train_data,min_freq=1)\n",
    "edits.build_vocab(train_data,min_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2fb1a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 (Create a iterator to loop over the data. Also separate batchs with \n",
    "#         similar length and pad the extra space)\n",
    "sort_key = lambda x: len(x.tokens)\n",
    "train_data_iterator,val_data_iterator,test_data_iterator = BucketIterator.splits((train_data,val_data,test_data),\n",
    "                                            batch_size=BATCH_SIZE, device= device,shuffle=True,sort_key=sort_key, sort_within_batch = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbdb648",
   "metadata": {},
   "source": [
    "#### data processing result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92295815",
   "metadata": {
    "hide_input": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49896"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10798651",
   "metadata": {
    "hide_input": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "378"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_data.examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e97f75e0",
   "metadata": {
    "hide_input": false,
    "lang": "en"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torchtext.legacy.data.dataset.TabularDataset object at 0x7f7d0e562b90>\n",
      "dict_keys(['tokens', 'edits'])\n",
      "dict_values([['[cls]', 'alistair', 'darling', 'is', 'expected', 'to', 'announce', 'details', 'of', 'tax', 'cuts', 'and', 'plans', 'to', 'increases', 'public', 'spending', '[sep]'], ['$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$transform_verb_vbz_vb', '$keep', '$append_.', '$keep']])\n"
     ]
    }
   ],
   "source": [
    "print(train_data)              # Tabular Data set object\n",
    "\n",
    "print(train_data[0].__dict__.keys())\n",
    "print(train_data[0].__dict__.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7074d5c4",
   "metadata": {
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 23])\n",
      "torch.Size([64, 23])\n"
     ]
    }
   ],
   "source": [
    "batch_1 = next(iter(train_data_iterator))\n",
    "print(batch_1.edits.shape)\n",
    "print(batch_1.tokens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3ef8b425",
   "metadata": {
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens.vocab.stoi['0'] = 0\n",
      "tokens.vocab.itos[0] = the\n",
      "edits.vocab.stoi['$keep'] = 0\n",
      "edits.vocab.itos[1] = $keep\n"
     ]
    }
   ],
   "source": [
    "#string to index\n",
    "print(f\"tokens.vocab.stoi['0'] = {tokens.vocab.stoi['']}\")\n",
    "print(f\"tokens.vocab.itos[0] = {tokens.vocab.itos[4]}\")\n",
    "print(f\"edits.vocab.stoi['$keep'] = {edits.vocab.stoi['0']}\")\n",
    "print(f\"edits.vocab.itos[1] = {edits.vocab.itos[4]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "547693f9",
   "metadata": {
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(tokens.vocab) = 64172\n",
      "len(edits.vocab) = 24\n"
     ]
    }
   ],
   "source": [
    "#length of vocabular create from the data set\n",
    "print(f\"len(tokens.vocab) = {len(tokens.vocab)}\")\n",
    "print(f\"len(edits.vocab) = {len(edits.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d3243d5",
   "metadata": {
    "hide_input": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(tokens.vocab.freqs.keys()) = 64168\n",
      "len(edits.vocab.freqs.keys()) = 20 \n",
      "\n",
      "edits.vocab.freqs = Counter({'$keep': 1191726, '$delete': 39872, '$replace_.': 7235, '$replace_,': 7183, '$transform_agreement_singular': 6220, '$append_.': 5167, '$append_,': 4905, '$append_the': 4686, '$replace_to': 3634, '$replace_the': 3574, '$replace_of': 3458, '$transform_verb_vbz_vb': 3253, '$replace_in': 2898, '$transform_verb_vbg_vb': 2714, '$transform_verb_vbn_vb': 2637, '$append_to': 2499, '$append_of': 2413, '$transform_agreement_plural': 2340, '$append_and': 2272, '$append_a': 2204})\n"
     ]
    }
   ],
   "source": [
    "# no. of unique words in tokens and edits\n",
    "print(f\"len(tokens.vocab.freqs.keys()) = {len(tokens.vocab.freqs.keys())}\")\n",
    "print(f\"len(edits.vocab.freqs.keys()) = {len(edits.vocab.freqs.keys())} \\n\")\n",
    "print(f\"edits.vocab.freqs = {edits.vocab.freqs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae29120c",
   "metadata": {
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens.vocab.vectors.shape = <torchtext.legacy.data.field.Field object at 0x7f7d0e5629d0>\n",
      "edits.vocab.vectors.shape = <torchtext.legacy.data.field.Field object at 0x7f7d0e562990>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#shape of vocabular create from the data set\n",
    "print(f\"tokens.vocab.vectors.shape = {tokens}\")\n",
    "print(f\"edits.vocab.vectors.shape = {edits}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7484bbd",
   "metadata": {
    "hide_input": false,
    "scrolled": true
   },
   "source": [
    "build vocab just takes unique tokens from the dataset and given a position and stores\n",
    "as a dictionary. when it is applied to the dataset the result comming from the \n",
    "bucket iteartor is just a postion no. from the build vocab and the rest is padded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b259fcb",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e1207c94",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 encoder_layer:int, # num of layer in encoder\n",
    "                 emb_dim:int, #embedding dimension\n",
    "                 head:int, #num of head\n",
    "                 src_vocab_size:int,\n",
    "                 trg_vocab_size:int,\n",
    "                 feedforward_dim:int, \n",
    "                 src_pad_idx:int,\n",
    "                 trg_pad_idx:int,\n",
    "                 device:str,\n",
    "                 dropout:float=0.0):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.head = head\n",
    "        self.emb_dim = emb_dim\n",
    "        self.device = device\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.trg_pad_idx = trg_pad_idx\n",
    "        \n",
    "        #Embedding layer\n",
    "        self.src_embedding_layer = nn.Embedding(src_vocab_size,emb_dim,device=device)\n",
    "        self.trg_embedding_layer = nn.Embedding(trg_vocab_size,emb_dim,device=device)\n",
    "        \n",
    "        #transformer layer\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=emb_dim, nhead=head, dim_feedforward=feedforward_dim, dropout=dropout,batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers,encoder_layer)\n",
    "        \n",
    "        # self.transformer = nn.Transformer(d_model = emb_dim,\n",
    "        #                                nhead = head,\n",
    "        #                                num_encoder_layers = encoder_layer,\n",
    "        #                                num_decoder_layers = decoder_layer,\n",
    "        #                                dropout = dropout,\n",
    "        #                                batch_first = True,\n",
    "        #                                device = device)\n",
    "        \n",
    "        #Linear Layer\n",
    "        self.linear_layer = nn.Linear(emb_dim,trg_vocab_size)\n",
    "        \n",
    "        # Dropout Layer\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # initrange = 1\n",
    "        # self.src_embedding_layer.weight.data.uniform_(-initrange, initrange)\n",
    "        # self.trg_embedding_layer.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "        # self.linear_layer.bias.data.zero_()\n",
    "        # self.linear_layer.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def positional_embedding(self,length = 200):\n",
    "        \n",
    "        position = torch.arange(length).unsqueeze(1).to(self.device)    # [batch_size, num_of_tokens]\n",
    "        denominator = torch.exp(torch.arange(0, self.emb_dim, 2) * (-math.log(10000.0) / self.emb_dim)).to(self.device)\n",
    "        \n",
    "        position_embedding = torch.zeros((length, self.emb_dim),device=self.device)\n",
    "        position_embedding[:,0::2] = torch.sin(position*denominator)\n",
    "        position_embedding[:,1::2] = torch.cos(position*denominator)\n",
    "        \n",
    "        position_embedding = position_embedding.unsqueeze(0)\n",
    "        # position_embedding = (1,lenght,emb_dim)\n",
    "        position_embedding.requires_grad = True\n",
    "        return position_embedding\n",
    "                                                      \n",
    "    def make_padding_mask(self,template,idx):\n",
    "        #mask = [batch size, src_len/trg_len]\n",
    "        return (template == idx)\n",
    "    \n",
    "    def trg_mask(self,trg):\n",
    "        mask = (torch.triu(torch.ones((trg, trg), device=self.device)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "    \n",
    "    def forward(self,\n",
    "                src : Tensor, #(batch_size,src_len)\n",
    "                trg : Tensor): #(batch_size,trg_len) \n",
    "                #in this case src_len == trg_len\n",
    "               \n",
    "        \n",
    "        batch_size , src_len  = src.shape\n",
    "        trg_len = src_len # depends upon the senario\n",
    "        \n",
    "        # Applying embedding layer\n",
    "        trg_mask = self.trg_mask(trg_len)\n",
    "        src_pad_mask = self.make_padding_mask(src,self.src_pad_idx)\n",
    "        trg_pad_mask = self.make_padding_mask(trg,self.trg_pad_idx)\n",
    "        \n",
    "        src_emb = self.src_embedding_layer(src)+self.positional_embedding(src_len)\n",
    "        trg_emb = self.trg_embedding_layer(trg)+self.positional_embedding(trg_len)\n",
    "        src_emb = self.dropout(src_emb).to(self.device)\n",
    "        trg_emb = self.dropout(trg_emb).to(self.device)\n",
    "        # src_emb = trg_emb = (batch_size,src_len/trg_len,emb_dim)\n",
    "        \n",
    "        # print(f\"src_emb[0] {src.shape}\")\n",
    "        # print(f\"trg_emb[0] {trg.shape}\")\n",
    "            \n",
    "        # Apply transformer layer\n",
    "        transformer_output = self.transformer_encoder(src_emb)\n",
    "        \n",
    "        # print(f\"encoder output {transformer_output.shape}\")\n",
    "        \n",
    "        # transformer_output = (batch_size,trg_len,emb_dim)\n",
    "        # print(f\"transformer_output {transformer_output[0]}\")\n",
    "        \n",
    "        # Apply Linear layer\n",
    "        output = self.linear_layer(transformer_output)\n",
    "        # print(f\"output {output.shape} \")\n",
    "        # output = (batch_size,trg_len,num_class)\n",
    "        \n",
    "        return output.permute(0,2,1)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea0798e",
   "metadata": {},
   "source": [
    "\n",
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "80f71b21",
   "metadata": {
    "hide_input": false,
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_model(model,data_iterator,optimizer,criterion,clip,n_classes):\n",
    "    \n",
    "    model.train()\n",
    "    epoch_loss,acc,f1_point = 0,0,0\n",
    "        \n",
    "    for i, batch in enumerate(train_data_iterator):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        src = batch.tokens.to(device)\n",
    "        trg = batch.edits.to(device)\n",
    "\n",
    "        \n",
    "        output = model(src, trg)\n",
    " \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        predicted = torch.argmax(output, dim=1)\n",
    "        \n",
    "        acc += accuracy(predicted, trg).item()\n",
    "        f1_point += f1_score(predicted, trg,average=\"macro\",num_classes=n_classes,mdmc_average='global').item()\n",
    "        \n",
    "    acc = 100.0 * acc / len(data_iterator)\n",
    "    f1_point = f1_point / len(data_iterator)\n",
    "    epoch_loss = epoch_loss / len(data_iterator)\n",
    "    \n",
    "    return (epoch_loss,acc,f1_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "921e2892",
   "metadata": {
    "hide_input": false,
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_iterator, criterion, n_classes):\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss,acc,f1_point = 0,0,0\n",
    "    f1_score_n_classes = torch.zeros(n_classes).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_iterator):\n",
    "            \n",
    "            src = batch.tokens.to(device)\n",
    "            trg = batch.edits.to(device)\n",
    "            \n",
    "            output = model(src, trg)\n",
    "\n",
    "            loss = criterion(output,trg)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            \n",
    "            predicted = torch.argmax(output, dim=1)\n",
    "            \n",
    "            acc += accuracy(predicted, trg).item() \n",
    "            f1_point += f1_score(predicted, trg,average=\"macro\",num_classes=n_classes,mdmc_average='global').item()\n",
    "            \n",
    "            \n",
    "            f1_score_n_classes += torch.nan_to_num(f1_score(predicted,trg, mdmc_average = 'global', average = 'none', num_classes = n_classes), nan = 0)\n",
    "            \n",
    "    f1_score_n_classes = f1_score_n_classes/len(data_iterator)\n",
    "    acc = 100.0 * acc / len(data_iterator)\n",
    "    f1_point = f1_point / len(data_iterator)\n",
    "    epoch_loss = epoch_loss / len(data_iterator)\n",
    "    \n",
    "    return (epoch_loss,acc,f1_point,f1_score_n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad412d2",
   "metadata": {},
   "source": [
    "### Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b07bcb53",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 50\n",
    "clip = 0.1\n",
    "num_encoder_layer = 6\n",
    "num_decoder_layer = 3\n",
    "INPUT_DIM = len(tokens.vocab)\n",
    "OUTPUT_DIM = len(edits.vocab)\n",
    "HIDDEN_DIM = 256\n",
    "EMBEDDING_DIM = 100\n",
    "heads = 4\n",
    "DROPOUT = 0.1\n",
    "PAD_IDX = tokens.vocab.stoi[tokens.pad_token]\n",
    "UNK_IDX = tokens.vocab.stoi[tokens.unk_token]\n",
    "EDIT_PAD_IDX = edits.vocab.stoi[edits.pad_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d6fa05d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "512/8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074921ca",
   "metadata": {},
   "source": [
    "### Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c38ca13d",
   "metadata": {
    "hide_input": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# model is created\n",
    "\n",
    "model = Seq2SeqTransformer(num_encoder_layer,EMBEDDING_DIM,heads,INPUT_DIM,OUTPUT_DIM,HIDDEN_DIM,PAD_IDX,EDIT_PAD_IDX,device,DROPOUT)\n",
    "# (num_encoder_layer,num_decoder_layer,EMBEDDING_DIM,heads,INPUT_DIM,OUTPUT_DIM,HIDDEN_DIM,PAD_IDX,EDIT_PAD_IDX,device,DROPOUT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "40d081c6",
   "metadata": {
    "hide_input": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Initialize optimizer and loss function\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=EDIT_PAD_IDX)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)#,weight_decay=weight_decay, amsgrad=amsgrad)\n",
    "# scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "n_total_steps = len(train_data_iterator)\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9fa205d5",
   "metadata": {
    "hide_input": false,
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 6,976,160 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "# initialize zero weights for unknown and padding tokens.\n",
    "\n",
    "# trainable parameters are printed\n",
    "\n",
    "count_parameters= lambda model:sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabddc3b",
   "metadata": {},
   "source": [
    "### Train and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "82b0f2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(f'runs/transformerEncoder/big_dataset/test_3')\n",
    "count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2223181f",
   "metadata": {
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50],\n",
      "        Train:       Loss: 0.448\n",
      "        Validation:  Loss: 0.364, Accuracy: 80.521,  F1 score: 0.219\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.8797, 0.0074, 0.8357, 0.6670, 0.0000,\n",
      "        0.0556, 0.0000, 0.0000, 0.0000, 0.0000, 0.0370, 0.0000, 0.4897, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [2/50],\n",
      "        Train:       Loss: 0.365\n",
      "        Validation:  Loss: 0.330, Accuracy: 80.842,  F1 score: 0.254\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.8811, 0.0537, 0.9070, 0.6618, 0.1877,\n",
      "        0.5262, 0.0000, 0.0000, 0.0000, 0.0000, 0.0476, 0.0000, 0.5222, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [3/50],\n",
      "        Train:       Loss: 0.343\n",
      "        Validation:  Loss: 0.313, Accuracy: 80.842,  F1 score: 0.274\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.8812, 0.1386, 0.8938, 0.6826, 0.3875,\n",
      "        0.5105, 0.0000, 0.0000, 0.0000, 0.0000, 0.0944, 0.1389, 0.5222, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [4/50],\n",
      "        Train:       Loss: 0.328\n",
      "        Validation:  Loss: 0.302, Accuracy: 80.926,  F1 score: 0.320\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.8814, 0.1543, 0.9156, 0.6549, 0.5762,\n",
      "        0.7310, 0.0000, 0.0000, 0.0000, 0.0000, 0.1513, 0.2611, 0.5063, 0.0556,\n",
      "        0.4045, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [5/50],\n",
      "        Train:       Loss: 0.316\n",
      "        Validation:  Loss: 0.287, Accuracy: 81.292,  F1 score: 0.328\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 0.9411, 0.8896, 0.1778, 0.9312, 0.6832, 0.5649,\n",
      "        0.8207, 0.0000, 0.0000, 0.1111, 0.0000, 0.0256, 0.2817, 0.4333, 0.1389,\n",
      "        0.4795, 0.0000, 0.0000, 0.0667, 0.0000, 0.0000], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [6/50],\n",
      "        Train:       Loss: 0.307\n",
      "        Validation:  Loss: 0.278, Accuracy: 81.446,  F1 score: 0.342\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.8847, 0.2028, 0.9502, 0.6758, 0.6082,\n",
      "        0.8804, 0.0000, 0.0000, 0.0000, 0.0000, 0.0476, 0.3095, 0.4730, 0.2452,\n",
      "        0.4947, 0.0000, 0.0000, 0.0417, 0.0000, 0.0000], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [7/50],\n",
      "        Train:       Loss: 0.299\n",
      "        Validation:  Loss: 0.268, Accuracy: 81.522,  F1 score: 0.332\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.8851, 0.2003, 0.9273, 0.6917, 0.5463,\n",
      "        0.8638, 0.0000, 0.0000, 0.0000, 0.0000, 0.0476, 0.2698, 0.4500, 0.2333,\n",
      "        0.4471, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [8/50],\n",
      "        Train:       Loss: 0.291\n",
      "        Validation:  Loss: 0.256, Accuracy: 81.705,  F1 score: 0.356\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.8860, 0.2904, 0.9788, 0.7003, 0.6093,\n",
      "        0.9069, 0.0000, 0.0000, 0.0000, 0.0000, 0.1386, 0.2722, 0.5222, 0.1944,\n",
      "        0.5212, 0.0000, 0.0000, 0.1000, 0.0000, 0.0000], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [9/50],\n",
      "        Train:       Loss: 0.283\n",
      "        Validation:  Loss: 0.248, Accuracy: 81.702,  F1 score: 0.367\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 0.9701, 0.8883, 0.2957, 0.9550, 0.6989, 0.6111,\n",
      "        0.9385, 0.0000, 0.0000, 0.0667, 0.0000, 0.0417, 0.3452, 0.5333, 0.1944,\n",
      "        0.5423, 0.0833, 0.0833, 0.1157, 0.0000, 0.0000], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [10/50],\n",
      "        Train:       Loss: 0.277\n",
      "        Validation:  Loss: 0.240, Accuracy: 81.714,  F1 score: 0.377\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 0.9588, 0.8897, 0.3254, 0.9292, 0.7130, 0.5482,\n",
      "        0.9195, 0.0000, 0.0000, 0.1222, 0.0417, 0.1446, 0.3591, 0.5137, 0.2778,\n",
      "        0.5219, 0.0833, 0.1111, 0.1417, 0.0000, 0.0000], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [11/50],\n",
      "        Train:       Loss: 0.270\n",
      "        Validation:  Loss: 0.231, Accuracy: 81.904,  F1 score: 0.384\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.8871, 0.3082, 0.9560, 0.7369, 0.6445,\n",
      "        0.9374, 0.0000, 0.0000, 0.1222, 0.0000, 0.0417, 0.3333, 0.5333, 0.3980,\n",
      "        0.5620, 0.0833, 0.1111, 0.1000, 0.0000, 0.0000], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [12/50],\n",
      "        Train:       Loss: 0.264\n",
      "        Validation:  Loss: 0.238, Accuracy: 81.667,  F1 score: 0.364\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.8859, 0.2868, 0.8769, 0.6584, 0.5877,\n",
      "        0.6892, 0.0667, 0.0000, 0.3000, 0.0000, 0.1560, 0.2500, 0.4833, 0.2611,\n",
      "        0.5351, 0.0833, 0.0000, 0.1417, 0.0000, 0.0000], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [13/50],\n",
      "        Train:       Loss: 0.259\n",
      "        Validation:  Loss: 0.213, Accuracy: 82.199,  F1 score: 0.395\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.8889, 0.3605, 0.9550, 0.7559, 0.6451,\n",
      "        0.9357, 0.0000, 0.0000, 0.1778, 0.0000, 0.0667, 0.3512, 0.5306, 0.3278,\n",
      "        0.6811, 0.0833, 0.1111, 0.1417, 0.0000, 0.0000], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [14/50],\n",
      "        Train:       Loss: 0.251\n",
      "        Validation:  Loss: 0.202, Accuracy: 82.243,  F1 score: 0.415\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.8886, 0.3428, 0.9550, 0.7650, 0.6941,\n",
      "        0.9516, 0.0833, 0.0417, 0.2698, 0.0417, 0.1111, 0.4179, 0.5639, 0.3556,\n",
      "        0.6182, 0.0667, 0.1944, 0.1157, 0.0000, 0.0000], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [15/50],\n",
      "        Train:       Loss: 0.245\n",
      "        Validation:  Loss: 0.197, Accuracy: 82.340,  F1 score: 0.452\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.8891, 0.4119, 0.9462, 0.6983, 0.6677,\n",
      "        0.9430, 0.0833, 0.0476, 0.4796, 0.1000, 0.0417, 0.4476, 0.5020, 0.4341,\n",
      "        0.8093, 0.2000, 0.2315, 0.2157, 0.0000, 0.1667], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [16/50],\n",
      "        Train:       Loss: 0.240\n",
      "        Validation:  Loss: 0.190, Accuracy: 82.402,  F1 score: 0.452\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.8895, 0.4242, 0.9462, 0.7409, 0.6932,\n",
      "        0.9613, 0.0000, 0.0417, 0.3479, 0.0741, 0.3878, 0.4139, 0.5040, 0.3841,\n",
      "        0.8182, 0.2000, 0.3426, 0.1000, 0.0000, 0.0000], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [17/50],\n",
      "        Train:       Loss: 0.234\n",
      "        Validation:  Loss: 0.180, Accuracy: 82.665,  F1 score: 0.493\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.8914, 0.4613, 0.9415, 0.7654, 0.6394,\n",
      "        0.9430, 0.1726, 0.0417, 0.5111, 0.2803, 0.3286, 0.4944, 0.5333, 0.6083,\n",
      "        0.8303, 0.2000, 0.3545, 0.2587, 0.0000, 0.0000], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [18/50],\n",
      "        Train:       Loss: 0.230\n",
      "        Validation:  Loss: 0.171, Accuracy: 82.896,  F1 score: 0.489\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.8930, 0.4869, 0.9516, 0.7456, 0.6429,\n",
      "        0.9637, 0.1806, 0.1037, 0.5278, 0.1303, 0.3888, 0.4841, 0.5563, 0.4000,\n",
      "        0.8444, 0.1500, 0.3148, 0.2900, 0.0000, 0.1111], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [19/50],\n",
      "        Train:       Loss: 0.224\n",
      "        Validation:  Loss: 0.164, Accuracy: 83.029,  F1 score: 0.525\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.8933, 0.5223, 0.9557, 0.7630, 0.7750,\n",
      "        0.9725, 0.2235, 0.0000, 0.6345, 0.2136, 0.4405, 0.5095, 0.5500, 0.6635,\n",
      "        0.8788, 0.1333, 0.2981, 0.2545, 0.2143, 0.0833], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [20/50],\n",
      "        Train:       Loss: 0.221\n",
      "        Validation:  Loss: 0.163, Accuracy: 83.070,  F1 score: 0.536\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.8937, 0.4818, 0.9550, 0.7780, 0.8115,\n",
      "        0.9627, 0.2877, 0.0417, 0.6532, 0.2348, 0.5172, 0.5222, 0.5813, 0.5897,\n",
      "        0.8481, 0.1500, 0.3767, 0.2688, 0.2143, 0.0000], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [21/50],\n",
      "        Train:       Loss: 0.215\n",
      "        Validation:  Loss: 0.153, Accuracy: 83.248,  F1 score: 0.542\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.8949, 0.5635, 0.9550, 0.7893, 0.7863,\n",
      "        0.9627, 0.3841, 0.1074, 0.6472, 0.2081, 0.5868, 0.4074, 0.5333, 0.5675,\n",
      "        0.8813, 0.2167, 0.3101, 0.2774, 0.1667, 0.1111], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [22/50],\n",
      "        Train:       Loss: 0.210\n",
      "        Validation:  Loss: 0.146, Accuracy: 83.472,  F1 score: 0.568\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.8957, 0.5809, 0.9550, 0.8106, 0.8278,\n",
      "        0.9637, 0.2685, 0.1037, 0.7243, 0.2348, 0.5544, 0.6063, 0.5444, 0.6845,\n",
      "        0.9000, 0.2444, 0.2704, 0.2865, 0.3810, 0.1111], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [23/50],\n",
      "        Train:       Loss: 0.206\n",
      "        Validation:  Loss: 0.143, Accuracy: 83.587,  F1 score: 0.545\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.8962, 0.6247, 0.9912, 0.8083, 0.8234,\n",
      "        0.9921, 0.3577, 0.0667, 0.5302, 0.2803, 0.5926, 0.5119, 0.5333, 0.6591,\n",
      "        0.9057, 0.2000, 0.2870, 0.2212, 0.0476, 0.1111], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [24/50],\n",
      "        Train:       Loss: 0.203\n",
      "        Validation:  Loss: 0.142, Accuracy: 83.542,  F1 score: 0.560\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 0.4958, 0.9497, 0.5914, 0.9689, 0.8080, 0.8256,\n",
      "        0.9706, 0.3628, 0.1414, 0.7491, 0.1667, 0.5147, 0.6710, 0.5694, 0.5016,\n",
      "        0.8409, 0.3111, 0.3648, 0.3611, 0.3810, 0.2222], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [25/50],\n",
      "        Train:       Loss: 0.198\n",
      "        Validation:  Loss: 0.137, Accuracy: 83.813,  F1 score: 0.608\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 0.9221, 0.9027, 0.5826, 0.9870, 0.7923, 0.8519,\n",
      "        0.9921, 0.4286, 0.3254, 0.7585, 0.3144, 0.6007, 0.7373, 0.5508, 0.6512,\n",
      "        0.8815, 0.2167, 0.4365, 0.3222, 0.3167, 0.3056], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [26/50],\n",
      "        Train:       Loss: 0.193\n",
      "        Validation:  Loss: 0.130, Accuracy: 83.820,  F1 score: 0.601\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.8981, 0.6261, 0.9674, 0.8094, 0.8887,\n",
      "        0.9542, 0.3651, 0.3454, 0.6975, 0.2508, 0.5802, 0.6103, 0.5556, 0.5659,\n",
      "        0.7773, 0.3373, 0.3926, 0.4167, 0.3611, 0.3056], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [27/50],\n",
      "        Train:       Loss: 0.190\n",
      "        Validation:  Loss: 0.129, Accuracy: 83.815,  F1 score: 0.618\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 0.9987, 0.8978, 0.6121, 0.9674, 0.8256, 0.8624,\n",
      "        0.9725, 0.4889, 0.2519, 0.7643, 0.3349, 0.5038, 0.5873, 0.5778, 0.6984,\n",
      "        0.7514, 0.4389, 0.4132, 0.3115, 0.5278, 0.2222], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [28/50],\n",
      "        Train:       Loss: 0.186\n",
      "        Validation:  Loss: 0.123, Accuracy: 84.098,  F1 score: 0.627\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 0.9821, 0.8999, 0.6411, 0.9629, 0.8313, 0.8750,\n",
      "        0.9823, 0.5139, 0.2778, 0.8113, 0.2644, 0.6257, 0.6825, 0.5556, 0.6790,\n",
      "        0.8930, 0.3278, 0.6037, 0.3222, 0.3929, 0.1111], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [29/50],\n",
      "        Train:       Loss: 0.182\n",
      "        Validation:  Loss: 0.116, Accuracy: 84.241,  F1 score: 0.662\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.9002, 0.6687, 0.9795, 0.7751, 0.8846,\n",
      "        0.9823, 0.5294, 0.3422, 0.7769, 0.3429, 0.7512, 0.6452, 0.5694, 0.7048,\n",
      "        0.8939, 0.4500, 0.5704, 0.3650, 0.5278, 0.3611], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [30/50],\n",
      "        Train:       Loss: 0.179\n",
      "        Validation:  Loss: 0.112, Accuracy: 84.368,  F1 score: 0.672\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.9018, 0.6870, 0.9629, 0.8090, 0.8833,\n",
      "        0.9725, 0.5235, 0.3452, 0.7439, 0.3597, 0.7157, 0.6759, 0.5508, 0.9160,\n",
      "        0.9259, 0.5706, 0.4815, 0.4449, 0.4833, 0.2889], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [31/50],\n",
      "        Train:       Loss: 0.175\n",
      "        Validation:  Loss: 0.110, Accuracy: 84.419,  F1 score: 0.680\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.9019, 0.6633, 0.9629, 0.7500, 0.8227,\n",
      "        0.9725, 0.5657, 0.4346, 0.8206, 0.3508, 0.6344, 0.7619, 0.5576, 0.8552,\n",
      "        0.9242, 0.5167, 0.6412, 0.4188, 0.3611, 0.6000], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [32/50],\n",
      "        Train:       Loss: 0.172\n",
      "        Validation:  Loss: 0.107, Accuracy: 84.552,  F1 score: 0.702\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.9021, 0.7133, 0.9674, 0.7622, 0.8866,\n",
      "        0.9823, 0.5282, 0.5333, 0.7722, 0.4288, 0.6959, 0.7341, 0.6556, 0.8313,\n",
      "        0.9293, 0.5397, 0.6077, 0.4821, 0.4206, 0.6556], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [33/50],\n",
      "        Train:       Loss: 0.168\n",
      "        Validation:  Loss: 0.104, Accuracy: 84.592,  F1 score: 0.698\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.9024, 0.6706, 0.9602, 0.7975, 0.8497,\n",
      "        0.9823, 0.4929, 0.5957, 0.5904, 0.4290, 0.7200, 0.7722, 0.6175, 0.8730,\n",
      "        0.9444, 0.5333, 0.5704, 0.3712, 0.5595, 0.6111], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [34/50],\n",
      "        Train:       Loss: 0.165\n",
      "        Validation:  Loss: 0.098, Accuracy: 84.687,  F1 score: 0.706\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.9029, 0.7411, 0.9602, 0.8143, 0.9070,\n",
      "        0.9585, 0.5392, 0.5626, 0.7302, 0.3795, 0.6364, 0.7944, 0.5730, 0.8313,\n",
      "        0.7778, 0.7000, 0.6227, 0.4594, 0.5556, 0.6667], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [35/50],\n",
      "        Train:       Loss: 0.162\n",
      "        Validation:  Loss: 0.096, Accuracy: 84.765,  F1 score: 0.726\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.9037, 0.7025, 0.9912, 0.7860, 0.9036,\n",
      "        0.9921, 0.5806, 0.4950, 0.5728, 0.4386, 0.7161, 0.8370, 0.6111, 0.8278,\n",
      "        0.9057, 0.7500, 0.7333, 0.4316, 0.5873, 0.6889], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [36/50],\n",
      "        Train:       Loss: 0.158\n",
      "        Validation:  Loss: 0.096, Accuracy: 84.708,  F1 score: 0.713\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.9032, 0.7208, 0.9674, 0.8105, 0.8522,\n",
      "        0.9823, 0.5917, 0.4638, 0.7157, 0.3620, 0.7254, 0.7976, 0.6556, 0.9028,\n",
      "        0.9131, 0.6563, 0.7040, 0.3712, 0.6111, 0.4563], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [37/50],\n",
      "        Train:       Loss: 0.155\n",
      "        Validation:  Loss: 0.093, Accuracy: 84.872,  F1 score: 0.724\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.9043, 0.7316, 0.9788, 0.8143, 0.9097,\n",
      "        0.9725, 0.6561, 0.5996, 0.5787, 0.4017, 0.7142, 0.8626, 0.6556, 0.8492,\n",
      "        0.9060, 0.6204, 0.6444, 0.5429, 0.5873, 0.6222], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [38/50],\n",
      "        Train:       Loss: 0.153\n",
      "        Validation:  Loss: 0.087, Accuracy: 85.063,  F1 score: 0.720\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.9051, 0.7606, 0.9867, 0.8406, 0.9125,\n",
      "        0.9823, 0.5694, 0.5119, 0.6925, 0.4461, 0.7562, 0.8404, 0.6694, 0.6889,\n",
      "        0.9444, 0.6452, 0.7576, 0.3862, 0.3929, 0.6333], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [39/50],\n",
      "        Train:       Loss: 0.149\n",
      "        Validation:  Loss: 0.085, Accuracy: 85.065,  F1 score: 0.744\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.9053, 0.7431, 0.9538, 0.8483, 0.8923,\n",
      "        0.9694, 0.6627, 0.5679, 0.8194, 0.3700, 0.8094, 0.8626, 0.6472, 0.8492,\n",
      "        0.9444, 0.7481, 0.8040, 0.5317, 0.5040, 0.4389], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [40/50],\n",
      "        Train:       Loss: 0.146\n",
      "        Validation:  Loss: 0.080, Accuracy: 85.264,  F1 score: 0.748\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.9064, 0.7593, 0.9674, 0.8563, 0.8843,\n",
      "        0.9823, 0.6704, 0.7030, 0.7815, 0.4331, 0.7733, 0.8354, 0.5952, 0.7583,\n",
      "        0.9444, 0.7250, 0.8254, 0.4077, 0.4206, 0.7222], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [41/50],\n",
      "        Train:       Loss: 0.144\n",
      "        Validation:  Loss: 0.079, Accuracy: 85.265,  F1 score: 0.758\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.9062, 0.7819, 0.9602, 0.8578, 0.9097,\n",
      "        0.9823, 0.6611, 0.6320, 0.8015, 0.4206, 0.7647, 0.8626, 0.6714, 0.7917,\n",
      "        0.9615, 0.7841, 0.7500, 0.5159, 0.6706, 0.4841], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [42/50],\n",
      "        Train:       Loss: 0.141\n",
      "        Validation:  Loss: 0.078, Accuracy: 85.340,  F1 score: 0.761\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.9068, 0.7888, 0.9602, 0.8587, 0.9528,\n",
      "        0.9823, 0.7077, 0.6899, 0.7200, 0.4461, 0.7598, 0.8778, 0.6053, 0.8694,\n",
      "        0.9060, 0.6516, 0.7857, 0.5411, 0.6706, 0.5778], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [43/50],\n",
      "        Train:       Loss: 0.138\n",
      "        Validation:  Loss: 0.074, Accuracy: 85.405,  F1 score: 0.776\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.9071, 0.7910, 0.9795, 0.8647, 0.9161,\n",
      "        0.9823, 0.7371, 0.7226, 0.8444, 0.5815, 0.7566, 0.8817, 0.6917, 0.8926,\n",
      "        0.9444, 0.6452, 0.7262, 0.4744, 0.5873, 0.6667], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [44/50],\n",
      "        Train:       Loss: 0.136\n",
      "        Validation:  Loss: 0.069, Accuracy: 85.519,  F1 score: 0.791\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.9076, 0.7918, 0.9602, 0.8548, 0.9333,\n",
      "        0.9823, 0.8133, 0.6922, 0.7639, 0.5847, 0.8115, 0.9095, 0.6313, 0.8926,\n",
      "        0.9430, 0.7944, 0.7206, 0.5111, 0.6706, 0.7619], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [45/50],\n",
      "        Train:       Loss: 0.133\n",
      "        Validation:  Loss: 0.066, Accuracy: 85.602,  F1 score: 0.807\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.9077, 0.8070, 0.9674, 0.8933, 0.8684,\n",
      "        0.9823, 0.6924, 0.7812, 0.8889, 0.5847, 0.8353, 0.9039, 0.6000, 0.9815,\n",
      "        0.9206, 0.8040, 0.7619, 0.6624, 0.6667, 0.7778], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [46/50],\n",
      "        Train:       Loss: 0.130\n",
      "        Validation:  Loss: 0.062, Accuracy: 85.788,  F1 score: 0.795\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.9092, 0.8350, 0.9762, 0.8218, 0.9491,\n",
      "        0.9902, 0.7101, 0.7252, 0.8595, 0.5594, 0.8567, 0.8556, 0.6694, 0.9021,\n",
      "        0.8889, 0.8262, 0.8540, 0.6182, 0.7222, 0.6111], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [47/50],\n",
      "        Train:       Loss: 0.127\n",
      "        Validation:  Loss: 0.066, Accuracy: 85.553,  F1 score: 0.784\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.9077, 0.8015, 0.9762, 0.8972, 0.9332,\n",
      "        0.9902, 0.7722, 0.6686, 0.6690, 0.6626, 0.7704, 0.7944, 0.6556, 0.9206,\n",
      "        0.9333, 0.7786, 0.8651, 0.6340, 0.6984, 0.5897], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [48/50],\n",
      "        Train:       Loss: 0.125\n",
      "        Validation:  Loss: 0.061, Accuracy: 85.785,  F1 score: 0.816\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.9087, 0.8253, 0.9762, 0.9148, 0.9020,\n",
      "        0.9902, 0.7879, 0.7185, 0.8093, 0.6932, 0.8706, 0.8972, 0.6730, 0.9021,\n",
      "        0.9307, 0.8778, 0.8767, 0.4417, 0.6944, 0.8095], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [49/50],\n",
      "        Train:       Loss: 0.122\n",
      "        Validation:  Loss: 0.058, Accuracy: 85.840,  F1 score: 0.824\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.9090, 0.8428, 0.9689, 0.8912, 0.8903,\n",
      "        0.9902, 0.7954, 0.7595, 0.8556, 0.5673, 0.8463, 0.8148, 0.6415, 0.9259,\n",
      "        0.9762, 0.9333, 0.9101, 0.6245, 0.7222, 0.8095], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch [50/50],\n",
      "        Train:       Loss: 0.120\n",
      "        Validation:  Loss: 0.058, Accuracy: 85.793,  F1 score: 0.818\n",
      "        f1_score_n_class:-    \n",
      "        tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.9089, 0.8402, 0.9674, 0.9145, 0.9277,\n",
      "        0.9823, 0.8120, 0.7397, 0.8741, 0.5926, 0.7885, 0.9429, 0.6167, 0.9259,\n",
      "        0.9762, 0.8540, 0.7687, 0.6602, 0.7167, 0.7460], device='cuda:1')\n",
      "----------------------------------------------------------------------------------\n",
      "time take is 15.932 min\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter_ns()\n",
    "try:\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        train_loss,train_acc,train_f1_score = train_model(model,train_data_iterator,optimizer,criterion,clip,OUTPUT_DIM)\n",
    "        val_loss,val_acc,val_f1_score,val_f1_score_n_class = evaluate_model(model, val_data_iterator, criterion,OUTPUT_DIM)\n",
    "        \n",
    "        if epoch%5 == 0:\n",
    "            pass\n",
    "\n",
    "        print (f'''Epoch [{epoch+1}/{num_epochs}],\n",
    "        Train:       Loss: {train_loss:.3f}\n",
    "        Validation:  Loss: {val_loss:.3f}, Accuracy: {val_acc:.3f},  F1 score: {val_f1_score:.3f}\n",
    "        f1_score_n_class:-    \n",
    "        {val_f1_score_n_class}''')\n",
    "        print(\"----------------------------------------------------------------------------------\")\n",
    "        \n",
    "        writer.add_scalars('LOSS',     { 'Train' : train_loss   ,'Validation' : val_loss    },  epoch)\n",
    "        writer.add_scalars('ACCURACY', { 'Train': train_acc     ,'Validation': val_acc      }, epoch)\n",
    "        writer.add_scalars('F1 SCORE', { 'Train': train_f1_score,'Validation': val_f1_score }, epoch)\n",
    "    \n",
    "finally:\n",
    "    end = time.perf_counter_ns()\n",
    "    timetaken = (end-start)*1.66667*10**-11\n",
    "    print(f\"time take is {timetaken:.3f} min\")\n",
    "    # torch.save(model, path+'/model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b991dddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 0.283 Test accuracy 93.363 F1 score 0.318\n"
     ]
    }
   ],
   "source": [
    "test_loss,test_accuracy,f1,f2 = evaluate_model(model, test_data_iterator, criterion,OUTPUT_DIM)\n",
    "print(f\"Test Loss {test_loss:.3f} Test accuracy {test_accuracy:.3f} F1 score {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493e6dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing the hyerparameter to the tensor board\n",
    "writer.add_hparams({'learning_rate' : learning_rate, \n",
    "                    'Num_epochs': num_epochs,\n",
    "                    'input_dim' : INPUT_DIM,\n",
    "                    'output_dim' : OUTPUT_DIM,\n",
    "                    'hidden_dim' : HIDDEN_DIM,\n",
    "                    'embedding_dim' : EMBEDDING_DIM,\n",
    "                    'droppout' : DROPOUT,\n",
    "                    'train_data_len': len(train_data),\n",
    "                    'Val_data_len': len(test_data),\n",
    "                    'batch_size': BATCH_SIZE,\n",
    "                  },\n",
    "                  {\n",
    "                      \"test_loss\":test_loss,\n",
    "                      \"test_accuracy\":test_accuracy,\n",
    "                      \"test_f1_score\":f1\n",
    "                  })\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff9b4e3",
   "metadata": {},
   "source": [
    "### Rough work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5226a6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(2, 5, 4)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1531be7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(a, dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e857483a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(a, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2109004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_act = torch.Tensor([[2,1],[1,3]]).int()\n",
    "# batch size, tokens\n",
    "print(f\" output shape {y_act.shape}\")\n",
    "s1 = torch.Tensor([[[0,2,3,0],[5,0,1,3]],[[1,5,2,3],[1,5,6,13]]])\n",
    "# batch size, tokens, emb lay\n",
    "\n",
    "print(f\" predicted shape {s1.shape}\")\n",
    "y_pred = torch.argmax(s1,dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179b3637",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred)\n",
    "print(y_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214cd89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f1_score(y_act,s1))\n",
    "print(accuracy_score(y_act,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956cd47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_recall(y_pred, y_act, average=\"macro\",num_classes=4,mdmc_average='samplewise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7012aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_pred,y_act,average=\"macro\",num_classes=4,mdmc_average='global')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b2cf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "p, r = precision_recall(y_pred, y_act, average=\"macro\",num_classes=4,mdmc_average='global')\n",
    "print(p)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86b867e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(2*p.item()*r.item())/(p.item()+r.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24f019b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9aeae6e2",
   "metadata": {},
   "source": [
    "###  THE END"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3.7.13 ('nn1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "316px",
    "width": "201px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "neural network",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "685px",
    "left": "26px",
    "top": "111.141px",
    "width": "218.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 337.852,
   "position": {
    "height": "359.852px",
    "left": "725px",
    "right": "20px",
    "top": "109px",
    "width": "544px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "6aceee38bda3a0efe7110e755f54df8f70e65ef87b8887aae7013a199e6971f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
