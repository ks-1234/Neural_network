{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd26723d",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b32f2f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.legacy.data import Field, TabularDataset, BucketIterator\n",
    "from torchtext.legacy import datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8895062d",
   "metadata": {},
   "source": [
    "### HyperParameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4d545ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hypa\n",
    "BATCH_SIZE = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9905bc",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0fa85690",
   "metadata": {},
   "source": [
    "1. fetch the data from the file. Using field and tabulardataset\n",
    "2. Build a vocab.\n",
    "3. Create a iterator to loop over the data. Also separate batchs with similar length and pad the extra space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ef1ee0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "removeTokens = lambda values: values[1:-1]   # function to remove [CLS] and [SEP] from the data set\n",
    "\n",
    "tokens = Field(sequential=True,use_vocab=True,preprocessing=removeTokens,lower=True,init_token=\"<sos>\",eos_token=\"<eos>\",pad_token=\"0\")\n",
    "edits = Field(sequential=True,use_vocab=True,preprocessing=removeTokens,lower=True,init_token=\"<sos>\",eos_token=\"<eos>\",pad_token=\"0\")\n",
    "\n",
    "fields = {'tokens':('tokens',tokens),'labels':('edits',edits)}\n",
    "\n",
    "train_data, test_data = TabularDataset.splits(path='data',train='ptrain.jsonl',test='val.jsonl',\n",
    "                                              format='json',fields=fields)\n",
    "\n",
    "# train_data is dataset with edits and tokens pair. in edits and tokens list of string is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e97f75e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torchtext.legacy.data.dataset.TabularDataset object at 0x7fa4e0037fd0>\n",
      "<class 'torchtext.legacy.data.example.Example'>\n",
      "dict_keys(['tokens', 'edits'])\n",
      "dict_values([['plus', ',', 'the', 'novelty', 'of', 'the', 'iphone', 'won', \"'t\", 'wear', 'off', ',', 'as', 'it', 'may', 'with', 'a', 'camcorder', ';', 'and', 'over', 'these', 'video', 'apps', 'have', 'fun', 'effects', 'that', 'a', 'camcorder', 'can', \"'t\", 'match', '.'], ['$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$replace_might', '$keep', '$keep', '$keep', '$replace_,', '$keep', '$delete', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep']])\n"
     ]
    }
   ],
   "source": [
    "print(train_data)\n",
    "print(type(train_data[0]))\n",
    "print(train_data[0].__dict__.keys())\n",
    "print(train_data[0].__dict__.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "70b1ac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens.build_vocab(train_data,min_freq=1,vectors='glove.6B.50d')\n",
    "edits.build_vocab(train_data,min_freq=1,vectors='glove.6B.50d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e9c0037a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torchtext.legacy.data.field.Field object at 0x7fa4e0037e90>\n",
      "<torchtext.legacy.vocab.Vocab object at 0x7fa4da7c9450>\n"
     ]
    }
   ],
   "source": [
    "print(tokens)\n",
    "print(tokens.vocab)\n",
    "# print(train_data[0].__dict__.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b2fb1a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_iterator, test_data_iterator = BucketIterator.splits((train_data,test_data),\n",
    "                                                                batch_size=BATCH_SIZE)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8d3243d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.vocab.stoi[\"<pad>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "baeb6d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos>'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.vocab.itos[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cf361265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edits.vocab.stoi[\"$keep\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8c9b7378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$keep'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edits.vocab.itos[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6e74e2db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([188, 50])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.vocab.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e1a729d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 50])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edits.vocab.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "79b6b88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184\n"
     ]
    }
   ],
   "source": [
    "print(len(tokens.vocab.freqs.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "db4fa80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "print(len(edits.vocab.freqs.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bca104e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'$keep': 240, '$delete': 9, '$replace_.': 4, '$transform_agreement_singular': 2, '$replace_might': 1, '$replace_,': 1, '$transform_verb_vbz_vb': 1, '$append_.': 1, '$transform_case_lower': 1, '$append_had': 1, '$replace_the': 1, '$append_said': 1, '$replace_no': 1, '$transform_verb_vbn_vbg': 1, '$replace_by': 1, '$append_yesterday': 1, '$replace_are': 1, '$replace_so': 1, '$append_for': 1, '$replace_what': 1, '$append_every': 1})\n"
     ]
    }
   ],
   "source": [
    "print(edits.vocab.freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3c5b3ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = set()\n",
    "for b in train_data_iterator:\n",
    "    s.add(b.edits)\n",
    "len(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff9b4e3",
   "metadata": {},
   "source": [
    "#### Rough work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4fdd3ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "l=['plus', ',', 'the', 'novelty', 'of', 'the', 'iphone', 'won', \"'t\", 'wear', 'off', ',', 'as', 'it', 'may', 'with', 'a', 'camcorder', ';', 'and', 'over', 'these', 'video', 'apps', 'have', 'fun', 'effects', 'that', 'a', 'camcorder', 'can', \"'t\", 'match', '.']\n",
    "l1=['$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$replace_might', '$keep', '$keep', '$keep', '$replace_,', '$keep', '$delete', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep']\n",
    "print(len(l))\n",
    "print(len(l1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fbb1b254",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Embedding as emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3aabdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embeddings, dim = 10,4 #10 - # of vocac size 4 - # of emdebbing dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "492ce96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(10, 4)\n",
      "torch.Size([10, 4])\n",
      "Parameter containing:\n",
      "tensor([[ 0.4167, -0.0727,  0.2211,  0.5794],\n",
      "        [-0.4527,  0.2912, -0.1159, -1.0680],\n",
      "        [-0.4339, -0.0446,  1.5780, -0.8122],\n",
      "        [ 0.5294,  1.0690, -0.8220, -1.6761],\n",
      "        [ 0.4288,  0.7014, -1.3402,  0.1515],\n",
      "        [-0.7275, -0.9264,  0.6392,  0.6486],\n",
      "        [ 0.8664, -0.6618,  0.4202, -1.0387],\n",
      "        [ 0.4916,  0.3138, -0.7286, -0.4734],\n",
      "        [-0.3453,  0.0581,  0.1727, -1.4853],\n",
      "        [ 0.4743, -0.3263, -0.3663,  0.0114]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "emb_1 = emb(n_embeddings, dim)\n",
    "print(emb_1)\n",
    "print(emb_1.weight.shape) #requires_grad=True therefore the matrix is learnable\n",
    "\n",
    "print(emb_1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b779edf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa9849f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nn3]",
   "language": "python",
   "name": "conda-env-nn3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
