{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd26723d",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b32f2f50",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.legacy.data import Field, TabularDataset, BucketIterator\n",
    "from torchtext.legacy import datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8895062d",
   "metadata": {},
   "source": [
    "### HyperParameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4d545ea5",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9905bc",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0fa85690",
   "metadata": {},
   "source": [
    "1. fetch the data from the file. Using field and tabulardataset\n",
    "2. Build a vocab.\n",
    "3. Create a iterator to loop over the data. Also separate batchs with similar length and pad the extra space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ef1ee0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "removeTokens = lambda values: values[1:-1]   # function to remove [CLS] and [SEP] from the data set\n",
    "\n",
    "tokens = Field(sequential=True,use_vocab=True,batch_first = True,preprocessing=removeTokens,lower=True,init_token=\"<sos>\",eos_token=\"<eos>\",pad_token=\"0\")\n",
    "edits = Field(sequential=True,use_vocab=True,batch_first = True,preprocessing=removeTokens,lower=True,init_token=\"<sos>\",eos_token=\"<eos>\",pad_token=\"0\")\n",
    "\n",
    "fields = {'tokens':('tokens',tokens),'labels':('edits',edits)}\n",
    "\n",
    "train_data, test_data = TabularDataset.splits(path='data',train='ptrain.jsonl',test='val.jsonl',\n",
    "                                              format='json',fields=fields)\n",
    "\n",
    "# train_data is dataset with edits and tokens pair. in edits and tokens list of string is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e97f75e0",
   "metadata": {
    "lang": "en"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torchtext.legacy.data.dataset.TabularDataset object at 0x7fd4481806d0>\n",
      "<class 'torchtext.legacy.data.example.Example'>\n",
      "dict_keys(['tokens', 'edits'])\n",
      "dict_values([['plus', ',', 'the', 'novelty', 'of', 'the', 'iphone', 'won', \"'t\", 'wear', 'off', ',', 'as', 'it', 'may', 'with', 'a', 'camcorder', ';', 'and', 'over', 'these', 'video', 'apps', 'have', 'fun', 'effects', 'that', 'a', 'camcorder', 'can', \"'t\", 'match', '.'], ['$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$replace_might', '$keep', '$keep', '$keep', '$replace_,', '$keep', '$delete', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep']])\n"
     ]
    }
   ],
   "source": [
    "print(train_data)\n",
    "print(type(train_data[0]))\n",
    "print(train_data[0].__dict__.keys())\n",
    "print(train_data[0].__dict__.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "70b1ac6d",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "tokens.build_vocab(train_data,min_freq=1,vectors='glove.6B.100d')\n",
    "edits.build_vocab(train_data,min_freq=1,vectors='glove.6B.100d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e9c0037a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torchtext.legacy.data.field.Field object at 0x7fd448180c90>\n",
      "<torchtext.legacy.vocab.Vocab object at 0x7fd448179e10>\n",
      "dict_keys(['tokens', 'edits'])\n",
      "dict_values([['so', 'even', 'now', ',', 'weekend', 'i', 'tell', 'my', 'children', 'to', 'bring', 'their', 'children', 'so', 'i', 'one', 'can', 'see', 'my', 'children', 'as', 'well', 'as', 'my', 'life', 'grandchildren', 'here', 'or', 'elsewhere', 'almost', 'once', 'a', 'week', ',', 'so', 'even', 'now', ',', 'weekend', 'i', 'tell', 'my', 'children', 'to', 'bring', 'their', 'children', 'so', 'i', 'one', 'can', 'see', 'my', 'children', 'as', 'well', 'as', 'my', 'life', 'grandchildren', 'here', 'or', 'elsewhere', 'almost', 'once', 'a', 'week', ','], ['$keep', '$keep', '$keep', '$append_every', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$delete', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$delete', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$replace_.']])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(tokens)\n",
    "print(tokens.vocab)\n",
    "print(train_data[0].__dict__.keys())\n",
    "print(train_data[-1].__dict__.values())\n",
    "print(len(train_data[-1].__dict__.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b2fb1a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_iterator, test_data_iterator = BucketIterator.splits((train_data,test_data),\n",
    "                                                                batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "45d8c9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_size_in_dataset = max(len(train_data))\n",
    "maxValue = max(train_data_iterator, key=lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0e6e3eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[torchtext.legacy.data.batch.Batch of size 5]\n",
       "\t[.tokens]:[torch.LongTensor of size 5x40]\n",
       "\t[.edits]:[torch.LongTensor of size 5x40]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxValue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d49be45",
   "metadata": {},
   "source": [
    "#### rough for data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e1ae244f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([43, 10])\n",
      "tensor([[  2,   2,   2,   2,   2,   2,   2,   2,   2,   2],\n",
      "        [ 30, 152, 132, 167,  56,  15,  11,  42, 142, 119],\n",
      "        [ 77,  19,   5,   9, 179, 138, 163,  23,  87,  19],\n",
      "        [ 29, 115,   4,  58, 109,   5, 150,  27, 114, 156],\n",
      "        [  5,  23, 120,  83,  35,   7, 127,  80, 160, 118],\n",
      "        [177,  34,   6,  15, 154,   5, 146,  10,  37, 122],\n",
      "        [ 26,  62,   4,  28,  47,  24,  15,  44, 117,  50],\n",
      "        [159,  10, 103,  34,  49,   6,   7,  69,  60,   4],\n",
      "        [ 16,  25, 182, 140,   5,  55, 145,   6,   7,  11],\n",
      "        [ 14,  91,  18,  38, 180,  93,  17, 157, 129, 153],\n",
      "        [ 10,   4, 174,  98,  82,  29,  32,  66, 170,  11],\n",
      "        [ 57, 168, 121,  78, 101, 151,  84,   9,   6,   4],\n",
      "        [ 32,  71,   5, 184, 137, 133,   5, 131,  81, 107],\n",
      "        [ 14, 165,  12,  86,  41,  48,  11,  10, 105,   5],\n",
      "        [ 30,   4, 104,   4,  20, 123,  52,  97,   9,   3],\n",
      "        [ 26, 183, 111, 116,   3,   4,  94, 134,   4,   1],\n",
      "        [125, 136,  17,  74,   1, 175,   8, 147,  72,   1],\n",
      "        [ 13, 144,   7, 185,   1, 171,   3,   3, 149,   1],\n",
      "        [141,   4,  22,  68,   1,  31,   1,   1,   6,   1],\n",
      "        [ 16,  90,  20,   4,   1,  45,   1,   1, 158,   1],\n",
      "        [ 14,  67,   9,  61,   1,  17,   1,   1, 139,   1],\n",
      "        [ 12,   5, 128,   6,   1,  21,   1,   1,   5,   1],\n",
      "        [178,  51, 162, 187,   1, 102,   1,   1,   4,   1],\n",
      "        [ 12,   4, 172,  36,   1,  65,   1,   1, 166,   1],\n",
      "        [ 16,  64,  46,  54,   1,  13,   1,   1,  27,   1],\n",
      "        [108,  63,  25,   6,   1,  70,   1,   1,  21,   1],\n",
      "        [ 89,   6,  88,  33,   1, 161,   1,   1,  75,   1],\n",
      "        [ 95,   4,  73,  96,   1,   4,   1,   1,  24,   1],\n",
      "        [126,  85,  31,   5,   1,  92,   1,   1,   6,   1],\n",
      "        [ 76, 155,   7,  40,   1,   8,   1,   1,  39,   1],\n",
      "        [ 43,   9,  22,  10,   1,   3,   1,   1, 186,   1],\n",
      "        [124, 106,  13,   4,   1,   1,   1,   1, 100,   1],\n",
      "        [  7, 169,  18,  33,   1,   1,   1,   1, 181,   1],\n",
      "        [176, 143, 110,  59,   1,   1,   1,   1,  79,   1],\n",
      "        [  5,  53,   8, 130,   1,   1,   1,   1,   4,   1],\n",
      "        [  3, 164,   3, 135,   1,   1,   1,   1, 148,   1],\n",
      "        [  1, 113,   1, 173,   1,   1,   1,   1,   6,   1],\n",
      "        [  1,   5,   1,   4,   1,   1,   1,   1,  99,   1],\n",
      "        [  1,   3,   1, 112,   1,   1,   1,   1,   8,   1],\n",
      "        [  1,   1,   1,   6,   1,   1,   1,   1,   3,   1],\n",
      "        [  1,   1,   1,  28,   1,   1,   1,   1,   1,   1],\n",
      "        [  1,   1,   1,   8,   1,   1,   1,   1,   1,   1],\n",
      "        [  1,   1,   1,   3,   1,   1,   1,   1,   1,   1]])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_data_iterator:\n",
    "    print(batch.tokens.shape)\n",
    "    print(batch.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c968f24c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  2,   2,   2,   2,   2,   2,   2,   2,   2,   2],\n",
      "        [ 11, 167,  30,  42,  15, 142, 152,  56, 119, 132],\n",
      "        [163,   9,  77,  23, 138,  87,  19, 179,  19,   5],\n",
      "        [150,  58,  29,  27,   5, 114, 115, 109, 156,   4],\n",
      "        [127,  83,   5,  80,   7, 160,  23,  35, 118, 120],\n",
      "        [146,  15, 177,  10,   5,  37,  34, 154, 122,   6],\n",
      "        [ 15,  28,  26,  44,  24, 117,  62,  47,  50,   4],\n",
      "        [  7,  34, 159,  69,   6,  60,  10,  49,   4, 103],\n",
      "        [145, 140,  16,   6,  55,   7,  25,   5,  11, 182],\n",
      "        [ 17,  38,  14, 157,  93, 129,  91, 180, 153,  18],\n",
      "        [ 32,  98,  10,  66,  29, 170,   4,  82,  11, 174],\n",
      "        [ 84,  78,  57,   9, 151,   6, 168, 101,   4, 121],\n",
      "        [  5, 184,  32, 131, 133,  81,  71, 137, 107,   5],\n",
      "        [ 11,  86,  14,  10,  48, 105, 165,  41,   5,  12],\n",
      "        [ 52,   4,  30,  97, 123,   9,   4,  20,   3, 104],\n",
      "        [ 94, 116,  26, 134,   4,   4, 183,   3,   1, 111],\n",
      "        [  8,  74, 125, 147, 175,  72, 136,   1,   1,  17],\n",
      "        [  3, 185,  13,   3, 171, 149, 144,   1,   1,   7],\n",
      "        [  1,  68, 141,   1,  31,   6,   4,   1,   1,  22],\n",
      "        [  1,   4,  16,   1,  45, 158,  90,   1,   1,  20],\n",
      "        [  1,  61,  14,   1,  17, 139,  67,   1,   1,   9],\n",
      "        [  1,   6,  12,   1,  21,   5,   5,   1,   1, 128],\n",
      "        [  1, 187, 178,   1, 102,   4,  51,   1,   1, 162],\n",
      "        [  1,  36,  12,   1,  65, 166,   4,   1,   1, 172],\n",
      "        [  1,  54,  16,   1,  13,  27,  64,   1,   1,  46],\n",
      "        [  1,   6, 108,   1,  70,  21,  63,   1,   1,  25],\n",
      "        [  1,  33,  89,   1, 161,  75,   6,   1,   1,  88],\n",
      "        [  1,  96,  95,   1,   4,  24,   4,   1,   1,  73],\n",
      "        [  1,   5, 126,   1,  92,   6,  85,   1,   1,  31],\n",
      "        [  1,  40,  76,   1,   8,  39, 155,   1,   1,   7],\n",
      "        [  1,  10,  43,   1,   3, 186,   9,   1,   1,  22],\n",
      "        [  1,   4, 124,   1,   1, 100, 106,   1,   1,  13],\n",
      "        [  1,  33,   7,   1,   1, 181, 169,   1,   1,  18],\n",
      "        [  1,  59, 176,   1,   1,  79, 143,   1,   1, 110],\n",
      "        [  1, 130,   5,   1,   1,   4,  53,   1,   1,   8],\n",
      "        [  1, 135,   3,   1,   1, 148, 164,   1,   1,   3],\n",
      "        [  1, 173,   1,   1,   1,   6, 113,   1,   1,   1],\n",
      "        [  1,   4,   1,   1,   1,  99,   5,   1,   1,   1],\n",
      "        [  1, 112,   1,   1,   1,   8,   3,   1,   1,   1],\n",
      "        [  1,   6,   1,   1,   1,   3,   1,   1,   1,   1],\n",
      "        [  1,  28,   1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  1,   8,   1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  1,   3,   1,   1,   1,   1,   1,   1,   1,   1]])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_data_iterator:\n",
    "    print(batch.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8d3243d5",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens.vocab.stoi['$$$'] = 0\n",
      "tokens.vocab.itos[0] = <unk>\n",
      "edits.vocab.stoi['$keep'] = 4\n",
      "edits.vocab.itos[4] = $keep\n",
      "\n",
      "len(tokens.vocab) = 188\n",
      "len(edits.vocab) = 25\n",
      "\n",
      "tokens.vocab.vectors.shape = torch.Size([188, 100])\n",
      "edits.vocab.vectors.shape = torch.Size([25, 100])\n",
      "\n",
      "len(tokens.vocab.freqs.keys()) = 184\n",
      "len(edits.vocab.freqs.keys()) = 21 \n",
      "\n",
      "edits.vocab.freqs = Counter({'$keep': 240, '$delete': 9, '$replace_.': 4, '$transform_agreement_singular': 2, '$replace_might': 1, '$replace_,': 1, '$transform_verb_vbz_vb': 1, '$append_.': 1, '$transform_case_lower': 1, '$append_had': 1, '$replace_the': 1, '$append_said': 1, '$replace_no': 1, '$transform_verb_vbn_vbg': 1, '$replace_by': 1, '$append_yesterday': 1, '$replace_are': 1, '$replace_so': 1, '$append_for': 1, '$replace_what': 1, '$append_every': 1})\n"
     ]
    }
   ],
   "source": [
    "#string to index\n",
    "print(f\"tokens.vocab.stoi['$$$'] = {tokens.vocab.stoi['$$$']}\")\n",
    "print(f\"tokens.vocab.itos[0] = {tokens.vocab.itos[0]}\")\n",
    "print(f\"edits.vocab.stoi['$keep'] = {edits.vocab.stoi['$keep']}\")\n",
    "print(f\"edits.vocab.itos[4] = {edits.vocab.itos[4]}\")\n",
    "print()\n",
    "\n",
    "#length of vocabular create from the data set\n",
    "print(f\"len(tokens.vocab) = {len(tokens.vocab)}\")\n",
    "print(f\"len(edits.vocab) = {len(edits.vocab)}\")\n",
    "print()\n",
    "\n",
    "#shape of vocabular create from the data set\n",
    "print(f\"tokens.vocab.vectors.shape = {tokens.vocab.vectors.shape}\")\n",
    "print(f\"edits.vocab.vectors.shape = {edits.vocab.vectors.shape}\")\n",
    "print()\n",
    "\n",
    "# no. of unique words in tokens and edits\n",
    "print(f\"len(tokens.vocab.freqs.keys()) = {len(tokens.vocab.freqs.keys())}\")\n",
    "print(f\"len(edits.vocab.freqs.keys()) = {len(edits.vocab.freqs.keys())} \\n\")\n",
    "print(f\"edits.vocab.freqs = {edits.vocab.freqs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e9a17c",
   "metadata": {},
   "source": [
    "### Model(rough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561831d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1d(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(max_size_in_dataset, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.convs = nn.ModuleList([nn.Conv1d(in_channels = embedding_dim, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = fs)\n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        #text = [batch size, sent len]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded = embedded.permute(0, 2, 1)\n",
    "        \n",
    "        #embedded = [batch size, emb dim, sent len]\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)) for conv in self.convs]\n",
    "            \n",
    "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
    "        \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "        \n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "            \n",
    "        return cat \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d6e0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 1, 1)\n",
    "        self.pool = nn.MaxPool1d(2, 2)\n",
    "        self.conv2 = nn.Conv1d(1, 1, 3)\n",
    "        self.conv2 = nn.Conv1d(1, 1, 5)\n",
    "        self.conv2 = nn.Conv1d(1, 1, 7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # -> n, 6, 14, 14\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # -> n, 16, 5, 5\n",
    "        x = x.view(-1, 16 * 5 * 5)            # -> n, 400\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70527919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df2661f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111de345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38568de7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50773f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "n_total_steps = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f71b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (tokens_list, edits_list) in enumerate(train_data_iterator):\n",
    "        # origin shape: [4, 3, 32, 32] = 4, 3, 1024\n",
    "        tokens_list = tokens_list.to(device)\n",
    "        edits_list = edits_list.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(tokens_list)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 2000 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print('Finished Training')\n",
    "PATH = './cnn.pth'\n",
    "torch.save(model.state_dict(), PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921e2892",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(10)]\n",
    "    n_class_samples = [0 for i in range(10)]\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network: {acc} %')\n",
    "\n",
    "    for i in range(10):\n",
    "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {classes[i]}: {acc} %')\n",
    "Footer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78c5387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cff9b4e3",
   "metadata": {},
   "source": [
    "### Rough work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdd3ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=['plus', ',', 'the', 'novelty', 'of', 'the', 'iphone', 'won', \"'t\", 'wear', 'off', ',', 'as', 'it', 'may', 'with', 'a', 'camcorder', ';', 'and', 'over', 'these', 'video', 'apps', 'have', 'fun', 'effects', 'that', 'a', 'camcorder', 'can', \"'t\", 'match', '.']\n",
    "l1=['$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$replace_might', '$keep', '$keep', '$keep', '$replace_,', '$keep', '$delete', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep']\n",
    "print(len(l))\n",
    "print(len(l1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fbb1b254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aabdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embeddings, dim = 10,4 #10 - # of vocac size 4 - # of emdebbing dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6b779edf",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "m = nn.Conv1d(1, 2, 3)\n",
    "input = torch.randn(2, 1, 5) # (batch size, no. of channel, # of words)\n",
    "# x = emb_1(input)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4fa9849f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 5])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2be40ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88501ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "492ce96f",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding Embedding(188, 50)\n",
      "embedding weight's shape torch.Size([188, 50])\n",
      "values of weight Parameter containing:\n",
      "tensor([[-2.2020, -1.5676,  1.0959,  ..., -1.5418,  1.0299, -0.1639],\n",
      "        [ 0.4356,  0.5537, -0.7752,  ..., -0.0168,  0.5911,  0.4768],\n",
      "        [-0.9705, -0.3136, -0.4529,  ..., -0.1166,  0.7507, -1.0787],\n",
      "        ...,\n",
      "        [-0.4359, -0.2323,  0.2142,  ...,  0.9488, -1.2057, -1.7878],\n",
      "        [ 1.1814, -1.2606,  0.5614,  ..., -1.7198,  0.3160, -0.1267],\n",
      "        [-0.1210, -0.7379,  0.1107,  ..., -0.8445,  0.0451,  1.6728]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import Embedding as emb\n",
    "\n",
    "emb_1 = emb(188, 50)\n",
    "print(f\"embedding {emb_1}\")\n",
    "print(f\"embedding weight's shape {emb_1.weight.shape}\") #requires_grad=True therefore the matrix is learnable\n",
    "\n",
    "print(f\"values of weight {emb_1.weight}\")\n",
    "\n",
    "for batch in train_data_iterator:\n",
    "    x = emb_1(batch.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1b19d554",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([43, 10, 50])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:nn3]",
   "language": "python",
   "name": "conda-env-nn3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "135px",
    "width": "160px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 337.852,
   "position": {
    "height": "359.852px",
    "left": "725px",
    "right": "20px",
    "top": "109px",
    "width": "544px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
