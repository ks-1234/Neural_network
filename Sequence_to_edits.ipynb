{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd26723d",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b32f2f50",
   "metadata": {
    "hide_input": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.legacy.data import Field, TabularDataset, BucketIterator\n",
    "from torchtext.legacy import datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "\n",
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cba2cf",
   "metadata": {},
   "source": [
    "#### parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d545ea5",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9905bc",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0fa85690",
   "metadata": {},
   "source": [
    "To do\n",
    "1. fetch the data from the file. Using field and tabulardataset\n",
    "2. Build a vocab.\n",
    "3. Create a iterator to loop over the data. Also separate batchs with similar length and pad the extra space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef1ee0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1\n",
    "\n",
    "removeTokens = lambda values: values[1:-1]   # function to remove [CLS] and [SEP] from the data set\n",
    "\n",
    "tokens = Field(sequential=True,use_vocab=True,batch_first = True,preprocessing=removeTokens,lower=True,pad_token=\"0\")\n",
    "edits = Field(sequential=True,use_vocab=True,batch_first = True,preprocessing=removeTokens,lower=True,pad_token=\"0\")\n",
    "\n",
    "fields = {'tokens':('tokens',tokens),'labels':('edits',edits)}\n",
    "\n",
    "train_data, test_data = TabularDataset.splits(path='data',train='ptrain.jsonl',test='val.jsonl',\n",
    "                                              format='json',fields=fields)\n",
    "\n",
    "# train_data is dataset with edits and tokens pair. in edits and tokens list of string is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e97f75e0",
   "metadata": {
    "lang": "en"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torchtext.legacy.data.dataset.TabularDataset object at 0x7fb5e27f1e50>\n",
      "dict_keys(['tokens', 'edits'])\n",
      "dict_values([['plus', ',', 'the', 'novelty', 'of', 'the', 'iphone', 'won', \"'t\", 'wear', 'off', ',', 'as', 'it', 'may', 'with', 'a', 'camcorder', ';', 'and', 'over', 'these', 'video', 'apps', 'have', 'fun', 'effects', 'that', 'a', 'camcorder', 'can', \"'t\", 'match', '.'], ['$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$replace_might', '$keep', '$keep', '$keep', '$replace_,', '$keep', '$delete', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep']])\n"
     ]
    }
   ],
   "source": [
    "print(train_data)              # Tabular Data set object\n",
    "\n",
    "print(train_data[0].__dict__.keys())\n",
    "print(train_data[0].__dict__.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "518a8248",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<torchtext.legacy.data.example.Example at 0x7fb5e2163450>,\n",
       " <torchtext.legacy.data.example.Example at 0x7fb5e2224d90>,\n",
       " <torchtext.legacy.data.example.Example at 0x7fb5e1bc7850>,\n",
       " <torchtext.legacy.data.example.Example at 0x7fb5e21d0950>,\n",
       " <torchtext.legacy.data.example.Example at 0x7fb5e1fe7f50>,\n",
       " <torchtext.legacy.data.example.Example at 0x7fb5e27f1b10>,\n",
       " <torchtext.legacy.data.example.Example at 0x7fb5e21d0410>,\n",
       " <torchtext.legacy.data.example.Example at 0x7fb5e27f1750>,\n",
       " <torchtext.legacy.data.example.Example at 0x7fb60337c3d0>,\n",
       " <torchtext.legacy.data.example.Example at 0x7fb5e187aa90>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.examples    # to print tokens of any row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70b1ac6d",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# step 2  Build a vocab\n",
    "\n",
    "tokens.build_vocab(train_data,min_freq=1,vectors='glove.6B.100d')\n",
    "edits.build_vocab(train_data,min_freq=1,vectors='glove.6B.100d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9c0037a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torchtext.legacy.data.field.Field object at 0x7fb5e27f15d0>\n",
      "<torchtext.legacy.vocab.Vocab object at 0x7fb5e1aa8ed0>\n",
      "dict_keys(['tokens', 'edits'])\n",
      "dict_values([['plus', ',', 'the', 'novelty', 'of', 'the', 'iphone', 'won', \"'t\", 'wear', 'off', ',', 'as', 'it', 'may', 'with', 'a', 'camcorder', ';', 'and', 'over', 'these', 'video', 'apps', 'have', 'fun', 'effects', 'that', 'a', 'camcorder', 'can', \"'t\", 'match', '.'], ['$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$replace_might', '$keep', '$keep', '$keep', '$replace_,', '$keep', '$delete', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep']])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(tokens)   # field object\n",
    "print(tokens.vocab)   #vocab object\n",
    "print(train_data[0].__dict__.keys())\n",
    "print(train_data[0].__dict__.values())\n",
    "print(len(train_data[3].__dict__.values()))\n",
    "\n",
    "# Note: even after the building vocab the train data will not change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b2fb1a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 (Create a iterator to loop over the data. Also separate batchs with \n",
    "#         similar length and pad the extra space)\n",
    "\n",
    "train_data_iterator, test_data_iterator = BucketIterator.splits((train_data,test_data),\n",
    "                                                                batch_size=5)#,sort_within_batch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7074d5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_1 = next(iter(train_data_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d34c838f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 41])\n",
      "torch.Size([5, 41])\n"
     ]
    }
   ],
   "source": [
    "print(batch_1.tokens.shape)\n",
    "print(batch_1.edits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ef8b425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens.vocab.stoi['$$$'] = 0\n",
      "tokens.vocab.itos[0] = <unk>\n",
      "edits.vocab.stoi['$keep'] = 2\n",
      "edits.vocab.itos[2] = $keep\n"
     ]
    }
   ],
   "source": [
    "#string to index\n",
    "print(f\"tokens.vocab.stoi['$$$'] = {tokens.vocab.stoi['$$$']}\")\n",
    "print(f\"tokens.vocab.itos[0] = {tokens.vocab.itos[0]}\")\n",
    "print(f\"edits.vocab.stoi['$keep'] = {edits.vocab.stoi['$keep']}\")\n",
    "print(f\"edits.vocab.itos[2] = {edits.vocab.itos[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "547693f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(tokens.vocab) = 174\n",
      "len(edits.vocab) = 22\n"
     ]
    }
   ],
   "source": [
    "#length of vocabular create from the data set\n",
    "print(f\"len(tokens.vocab) = {len(tokens.vocab)}\")\n",
    "print(f\"len(edits.vocab) = {len(edits.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d3243d5",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(tokens.vocab.freqs.keys()) = 172\n",
      "len(edits.vocab.freqs.keys()) = 20 \n",
      "\n",
      "edits.vocab.freqs = Counter({'$keep': 259, '$delete': 10, '$replace_.': 4, '$transform_agreement_singular': 2, '$append_every': 2, '$replace_might': 1, '$replace_,': 1, '$transform_verb_vbz_vb': 1, '$append_.': 1, '$transform_case_lower': 1, '$append_had': 1, '$replace_the': 1, '$append_said': 1, '$replace_no': 1, '$transform_verb_vbn_vbg': 1, '$replace_by': 1, '$append_yesterday': 1, '$replace_so': 1, '$append_for': 1, '$replace_what': 1})\n"
     ]
    }
   ],
   "source": [
    "# no. of unique words in tokens and edits\n",
    "print(f\"len(tokens.vocab.freqs.keys()) = {len(tokens.vocab.freqs.keys())}\")\n",
    "print(f\"len(edits.vocab.freqs.keys()) = {len(edits.vocab.freqs.keys())} \\n\")\n",
    "print(f\"edits.vocab.freqs = {edits.vocab.freqs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae29120c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens.vocab.vectors.shape = torch.Size([174, 100])\n",
      "edits.vocab.vectors.shape = torch.Size([22, 100])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#shape of vocabular create from the data set\n",
    "print(f\"tokens.vocab.vectors.shape = {tokens.vocab.vectors.shape}\")\n",
    "print(f\"edits.vocab.vectors.shape = {edits.vocab.vectors.shape}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7484bbd",
   "metadata": {
    "hide_input": false,
    "scrolled": true
   },
   "source": [
    "build vocab just takes unique tokens from the dataset and given a position and stores\n",
    "as a dictionary. when it is applied to the dataset the result comming from the \n",
    "bucket iteartor is just a postion no. from the build vocab and the rest is padded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b259fcb",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9881b4ee",
   "metadata": {
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "class Seq_to_edits(nn.Module):\n",
    "    def __init__(self,token_vocab_size : int        # num of unique token in the entire dataset \n",
    "               ,edit_vocab_size : list             # [batch_size,max sentence size in the batch]\n",
    "               ,output_dim : list            # [batch_size,max sentence size in the batch]\n",
    "               ,embed_dim : int              # embedding dimension\n",
    "               ,num_of_filters : int         # to num of filters\n",
    "               ,filter_sizes : list          # list of sizes of each filter\n",
    "               ,dropout : int                # dropout percent ()\n",
    "               ,pad_index : int              # padding index from the vocab\n",
    "               ,max_lenght : int = 100):     # Maximum words in a list of tokens or sentence\n",
    "               \n",
    "        \n",
    "        \n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.token_embedding_layer = nn.Embedding(token_vocab_size,embed_dim)\n",
    "        self.position_embedding_layer = nn.Embedding(max_lenght,embed_dim)\n",
    "        \n",
    "        # Multiple conv 1D layers \n",
    "        self.conv_layers = nn.ModuleList([nn.Conv1d(in_channels = embed_dim,\n",
    "                                                    out_channels= embed_dim,\n",
    "                                                    kernel_size = filter_size,\n",
    "                                                    padding = \"same\") \n",
    "                                          for filter_size in filter_sizes])\n",
    "        \n",
    "        self.final_layer = nn.Linear(embed_dim, edit_vocab_size)\n",
    "        # Dropout layers\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, tokens):\n",
    "        \n",
    "        # tokens size is [batch_size, max sentence size in the batch/token size]\n",
    "        \n",
    "        batch_size , num_of_tokens = tokens.shape\n",
    "        \n",
    "        position = torch.arange(0,num_of_tokens).unsqueeze(0)         # [1,num_of_tokens]\n",
    "        position = position.repeat(batch_size,1).to(self.device)    # [batch_size, num_of_tokens]\n",
    "        \n",
    "        \n",
    "        # apply embedding layer\n",
    "        token_embeddings    = self.token_embedding_layer(tokens)\n",
    "        position_embeddings = self.position_embedding_layer(position)\n",
    "        \n",
    "        # token_embeddings = position_embeddings = [batch_size, num_of_tokens,embedding dimension]\n",
    "        \n",
    "        print(f\"embed dim = {token_embeddings.shape[2]}\")\n",
    "        combination = self.dropout(token_embeddings+position_embeddings)\n",
    "        # combination = [batch_size, num_of_tokens,embedding dimension]\n",
    "        \n",
    "        #permute for convolutional layer\n",
    "        conved = combination.permute(0, 2, 1) \n",
    "        \n",
    "        #conv_input = [batch size, emb dim, src len]\n",
    "        \n",
    "        #begin convolutional blocks...\n",
    "        \n",
    "        for i, conv_layer in enumerate(self.conv_layers):\n",
    "        \n",
    "            #pass through convolutional layer\n",
    "            conved = conv_layer(self.dropout(conved))\n",
    "            #conved = [batch size, emd dim, token len]\n",
    "            \n",
    "\n",
    "            #pass through GLU activation function\n",
    "            conved = F.relu(conved)\n",
    "\n",
    "            #conved = [batch size, emd dim, token len]\n",
    "        \n",
    "        conved = conved.squeeze(1).reshape(batch_size,100,-1).permute(0, 2, 1)\n",
    "        \n",
    "        output = self.final_layer(conved)\n",
    "         print(f\"output.shape = {output.shape}\") \n",
    "\n",
    "\n",
    "        return output.permute(0, 2, 1)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b07bcb53",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "num_epochs = 10\n",
    "INPUT_DIM = len(tokens.vocab)\n",
    "OUTPUT_DIM = len(edits.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "N_FILTERS = 3\n",
    "FILTER_SIZES = [3,4,5]\n",
    "OUTPUT_DIM = len(edits.vocab)\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = tokens.vocab.stoi[tokens.pad_token]\n",
    "UNK_IDX = tokens.vocab.stoi[tokens.unk_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c38ca13d",
   "metadata": {
    "hide_input": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# model is created\n",
    "\n",
    "model = Seq_to_edits(INPUT_DIM,OUTPUT_DIM,OUTPUT_DIM,EMBEDDING_DIM,N_FILTERS,FILTER_SIZES,DROPOUT,PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fa205d5",
   "metadata": {
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 149,922 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "# trainable parameters are printed\n",
    "\n",
    "count_parameters= lambda model:sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "862f3c77",
   "metadata": {
    "hide_input": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.6149,  0.9273,  0.5583,  ..., -0.0922, -0.0798, -1.2843],\n",
       "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
       "        ...,\n",
       "        [ 0.4221,  0.6307, -0.1291,  ...,  0.1045,  0.1854, -0.4767],\n",
       "        [ 0.2783,  0.4995,  0.2494,  ..., -0.3274, -0.3004,  0.0930],\n",
       "        [ 0.7090,  0.6810, -1.2128,  ...,  0.6917,  1.4080, -1.0227]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the pre-tained embeddings \n",
    "\n",
    "pretrained_embeddings = tokens.vocab.vectors\n",
    "\n",
    "model.token_embedding_layer.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c21b7ae",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# initialize zero weights for unknown and padding tokens.\n",
    "\n",
    "\n",
    "model.token_embedding_layer.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.token_embedding_layer.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40d081c6",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# Initialize optimizer and loss function\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "n_total_steps = len(train_data_iterator)\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "n_total_steps = len(train_data_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62dc9d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4c175d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function summary in module torchsummary.torchsummary:\n",
      "\n",
      "summary(model, input_size, batch_size=-1, device='cuda')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d236260",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f7907ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq_to_edits(\n",
       "  (token_embedding_layer): Embedding(174, 100)\n",
       "  (position_embedding_layer): Embedding(100, 100)\n",
       "  (conv_layers): ModuleList(\n",
       "    (0): Conv1d(100, 100, kernel_size=(3,), stride=(1,), padding=same)\n",
       "    (1): Conv1d(100, 100, kernel_size=(4,), stride=(1,), padding=same)\n",
       "    (2): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=same)\n",
       "  )\n",
       "  (final_layer): Linear(in_features=100, out_features=22, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5406f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96e9a17c",
   "metadata": {},
   "source": [
    "### Model(rough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50773f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80f71b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bs x tok_len 5 34\n",
      "embed dim = 100\n",
      "conv_input  = torch.Size([5, 100, 34])\n",
      "i = 0 \n",
      " conved = torch.Size([5, 100, 34])\n",
      "i = 1 \n",
      " conved = torch.Size([5, 100, 34])\n",
      "i = 2 \n",
      " conved = torch.Size([5, 100, 34])\n",
      "conved.shape = torch.Size([5, 34, 100])\n",
      "output.shape = torch.Size([5, 34, 22])\n",
      "bs x tok_len 5 41\n",
      "embed dim = 100\n",
      "conv_input  = torch.Size([5, 100, 41])\n",
      "i = 0 \n",
      " conved = torch.Size([5, 100, 41])\n",
      "i = 1 \n",
      " conved = torch.Size([5, 100, 41])\n",
      "i = 2 \n",
      " conved = torch.Size([5, 100, 41])\n",
      "conved.shape = torch.Size([5, 41, 100])\n",
      "output.shape = torch.Size([5, 41, 22])\n",
      "bs x tok_len 5 37\n",
      "embed dim = 100\n",
      "conv_input  = torch.Size([5, 100, 37])\n",
      "i = 0 \n",
      " conved = torch.Size([5, 100, 37])\n",
      "i = 1 \n",
      " conved = torch.Size([5, 100, 37])\n",
      "i = 2 \n",
      " conved = torch.Size([5, 100, 37])\n",
      "conved.shape = torch.Size([5, 37, 100])\n",
      "output.shape = torch.Size([5, 37, 22])\n",
      "bs x tok_len 5 37\n",
      "embed dim = 100\n",
      "conv_input  = torch.Size([5, 100, 37])\n",
      "i = 0 \n",
      " conved = torch.Size([5, 100, 37])\n",
      "i = 1 \n",
      " conved = torch.Size([5, 100, 37])\n",
      "i = 2 \n",
      " conved = torch.Size([5, 100, 37])\n",
      "conved.shape = torch.Size([5, 37, 100])\n",
      "output.shape = torch.Size([5, 37, 22])\n",
      "bs x tok_len 5 38\n",
      "embed dim = 100\n",
      "conv_input  = torch.Size([5, 100, 38])\n",
      "i = 0 \n",
      " conved = torch.Size([5, 100, 38])\n",
      "i = 1 \n",
      " conved = torch.Size([5, 100, 38])\n",
      "i = 2 \n",
      " conved = torch.Size([5, 100, 38])\n",
      "conved.shape = torch.Size([5, 38, 100])\n",
      "output.shape = torch.Size([5, 38, 22])\n",
      "bs x tok_len 5 37\n",
      "embed dim = 100\n",
      "conv_input  = torch.Size([5, 100, 37])\n",
      "i = 0 \n",
      " conved = torch.Size([5, 100, 37])\n",
      "i = 1 \n",
      " conved = torch.Size([5, 100, 37])\n",
      "i = 2 \n",
      " conved = torch.Size([5, 100, 37])\n",
      "conved.shape = torch.Size([5, 37, 100])\n",
      "output.shape = torch.Size([5, 37, 22])\n",
      "bs x tok_len 5 38\n",
      "embed dim = 100\n",
      "conv_input  = torch.Size([5, 100, 38])\n",
      "i = 0 \n",
      " conved = torch.Size([5, 100, 38])\n",
      "i = 1 \n",
      " conved = torch.Size([5, 100, 38])\n",
      "i = 2 \n",
      " conved = torch.Size([5, 100, 38])\n",
      "conved.shape = torch.Size([5, 38, 100])\n",
      "output.shape = torch.Size([5, 38, 22])\n",
      "bs x tok_len 5 38\n",
      "embed dim = 100\n",
      "conv_input  = torch.Size([5, 100, 38])\n",
      "i = 0 \n",
      " conved = torch.Size([5, 100, 38])\n",
      "i = 1 \n",
      " conved = torch.Size([5, 100, 38])\n",
      "i = 2 \n",
      " conved = torch.Size([5, 100, 38])\n",
      "conved.shape = torch.Size([5, 38, 100])\n",
      "output.shape = torch.Size([5, 38, 22])\n",
      "bs x tok_len 5 37\n",
      "embed dim = 100\n",
      "conv_input  = torch.Size([5, 100, 37])\n",
      "i = 0 \n",
      " conved = torch.Size([5, 100, 37])\n",
      "i = 1 \n",
      " conved = torch.Size([5, 100, 37])\n",
      "i = 2 \n",
      " conved = torch.Size([5, 100, 37])\n",
      "conved.shape = torch.Size([5, 37, 100])\n",
      "output.shape = torch.Size([5, 37, 22])\n",
      "bs x tok_len 5 38\n",
      "embed dim = 100\n",
      "conv_input  = torch.Size([5, 100, 38])\n",
      "i = 0 \n",
      " conved = torch.Size([5, 100, 38])\n",
      "i = 1 \n",
      " conved = torch.Size([5, 100, 38])\n",
      "i = 2 \n",
      " conved = torch.Size([5, 100, 38])\n",
      "conved.shape = torch.Size([5, 38, 100])\n",
      "output.shape = torch.Size([5, 38, 22])\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kirthika-13378/opt/anaconda3/envs/nn3/lib/python3.7/site-packages/torch/nn/modules/conv.py:295: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  ../aten/src/ATen/native/Convolution.cpp:660.)\n",
      "  self.padding, self.dilation, self.groups)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, batch in enumerate(train_data_iterator):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "        # converting to cpu or gpu variable\n",
    "        tokens_list = batch.tokens.to(device)\n",
    "        edits_list = batch.edits.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(tokens_list)\n",
    "        loss = criterion(outputs, edits_list)\n",
    "\n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        break \n",
    "        if (i+1) % 2000 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "\n",
    "print('Finished Training')\n",
    "PATH = './cnn.pth'\n",
    "torch.save(model.state_dict(), PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "921e2892",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'Example' and 'Example'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/s7/9q6vwr352txcx0rs9vflhmrj4x6wvg/T/ipykernel_14614/1749257166.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_data_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nn3/lib/python3.7/site-packages/torchtext/legacy/data/iterator.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminibatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0;31m# fast-forward if loaded from state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nn3/lib/python3.7/site-packages/torchtext/legacy/data/iterator.py\u001b[0m in \u001b[0;36minit_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_state_this_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_shuffler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restored_from_state\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nn3/lib/python3.7/site-packages/torchtext/legacy/data/iterator.py\u001b[0m in \u001b[0;36mcreate_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m             self.batches = batch(self.data(), self.batch_size,\n\u001b[0m\u001b[1;32m    250\u001b[0m                                  self.batch_size_fn)\n\u001b[1;32m    251\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nn3/lib/python3.7/site-packages/torchtext/legacy/data/iterator.py\u001b[0m in \u001b[0;36mdata\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;34m\"\"\"Return the examples in the dataset in order, sorted, or shuffled.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_shuffler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'Example' and 'Example'"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "    \n",
    "epoch_loss = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for batch in test_data_iterator:\n",
    "\n",
    "        src = batch.tokens\n",
    "        trg = batch.edits\n",
    "\n",
    "        output, _ = model(src, trg)\n",
    "\n",
    "        #output = [batch size, trg len - 1, output dim]\n",
    "        #trg = [batch size, trg len]\n",
    "\n",
    "        output_dim = output.shape[-1]\n",
    "\n",
    "        output = output.contiguous().view(-1, output_dim)\n",
    "        trg = trg[:,1:].contiguous().view(-1)\n",
    "\n",
    "        #output = [batch size * trg len - 1, output dim]\n",
    "        #trg = [batch size * trg len - 1]\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "print( epoch_loss / len(iterator))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff9b4e3",
   "metadata": {},
   "source": [
    "### Rough work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdd3ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=['plus', ',', 'the', 'novelty', 'of', 'the', 'iphone', 'won', \"'t\", 'wear', 'off', ',', 'as', 'it', 'may', 'with', 'a', 'camcorder', ';', 'and', 'over', 'these', 'video', 'apps', 'have', 'fun', 'effects', 'that', 'a', 'camcorder', 'can', \"'t\", 'match', '.']\n",
    "l1=['$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$replace_might', '$keep', '$keep', '$keep', '$replace_,', '$keep', '$delete', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep', '$keep']\n",
    "print(len(l))\n",
    "print(len(l1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb1b254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7154c1f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aabdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embeddings, dim = 10,4 #10 - # of vocac size 4 - # of emdebbing dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b779edf",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "m = nn.Conv1d(1, 2, 3)\n",
    "input = torch.randn(2, 1, 5) # (batch size, no. of channel, # of words)\n",
    "# x = emb_1(input)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa9849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78c5387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd92e254",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72af8a52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492ce96f",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "from torch.nn import Embedding as emb\n",
    "\n",
    "emb_1 = emb(188, 50)\n",
    "print(f\"embedding {emb_1}\")\n",
    "print(f\"embedding weight's shape {emb_1.weight.shape}\") #requires_grad=True therefore the matrix is learnable\n",
    "\n",
    "print(f\"values of weight {emb_1.weight}\")\n",
    "\n",
    "for batch in train_data_iterator:\n",
    "    x = emb_1(batch.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8570b31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5331915f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1,2,4],[1, 2, 3]])\n",
    "print(x.shape)\n",
    "x=x.repeat(4, 2)\n",
    "print(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287c316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "N = 40\n",
    "C_in = 40\n",
    "L_in = 100\n",
    "inputs = torch.rand([N, C_in, L_in])\n",
    "padding = 3\n",
    "kernel_size = 3\n",
    "stride = 2\n",
    "C_out = 10\n",
    "x = torch.nn.Conv1d(C_in, C_out, kernel_size, stride=stride, padding=padding)\n",
    "y = x(inputs)\n",
    "print(y)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6f4695",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = torch.randn([2,4,5])\n",
    "\n",
    "# print(x_input)\n",
    "x_input = x_input.permute(0,2,1).reshape(2,-1).unsqueeze(1)\n",
    "print(x_input.shape)\n",
    "print(x_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e442ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nn.Conv1d(in_channels =1 ,out_channels= 1,kernel_size = 1,padding=\"same\")(x_input)\n",
    "b = nn.Conv1d(in_channels =1 ,out_channels= 1,kernel_size = 1,padding=\"same\")(a)\n",
    "c = nn.Conv1d(in_channels =1 ,out_channels= 1,kernel_size = 3,padding=\"same\")(b)\n",
    "d = nn.Conv1d(in_channels =1 ,out_channels= 1,kernel_size = 4,padding=\"same\")(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af6edc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"a = {a.shape}\")\n",
    "print(f\"b = {b.shape}\")\n",
    "print(f\"c = {c.shape}\")\n",
    "print(f\"d = {d.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f459c552",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = d.squeeze(1).reshape(2,5,-1)\n",
    "d.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06aa118",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"f = {f.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a473d14c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g = nn.Conv1d(in_channels =1 ,out_channels= 4,kernel_size = 3)(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74645c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"g = {g.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4246c4d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f5a530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfdc358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8644be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57359b11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91776938",
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aac3588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60d37a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c461f529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18872bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a40d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = torch.randn([2,4,5])\n",
    "\n",
    "# print(x_input)\n",
    "x_input = x_input.reshape(2,-1).unsqueeze(1)\n",
    "print(x_input.shape)\n",
    "print(x_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f25d69",
   "metadata": {
    "hide_input": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a1 = nn.Conv1d(in_channels =4 ,out_channels= 4,kernel_size = 2,padding=\"same\")(x_input)\n",
    "b1 = nn.Conv1d(in_channels =4 ,out_channels= 4,kernel_size = 1,padding=\"same\")(x_input)\n",
    "c1 = nn.Conv1d(in_channels =4 ,out_channels= 4,kernel_size = 3,padding=\"same\")(x_input)\n",
    "d1 = nn.Conv1d(in_channels =4 ,out_channels= 4,kernel_size = 4,padding=\"same\")(x_input)\n",
    "\n",
    "f1 = nn.Conv1d(in_channels = e1.shape[1],out_channels= 25,kernel_size = 1)(e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58624c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"a1 = {a1.shape}\")\n",
    "print(f\"b1 = {b1.shape}\")\n",
    "print(f\"c1 = {c1.shape}\")\n",
    "print(f\"d1 = {d1.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c18b54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = nn.Conv1d(in_channels =4 ,out_channels= 4,kernel_size = 2,padding=\"same\")(x_input)\n",
    "b1 = nn.Conv1d(in_channels =4 ,out_channels= 4,kernel_size = 1,padding=\"same\")(x_input)\n",
    "c1 = nn.Conv1d(in_channels =4 ,out_channels= 4,kernel_size = 3,padding=\"same\")(x_input)\n",
    "d1 = nn.Conv1d(in_channels =4 ,out_channels= 4,kernel_size = 4,padding=\"same\")(x_input)\n",
    "e1 = torch.cat([a1,b1,c1,d1],dim =1)\n",
    "f1 = nn.Conv1d(in_channels = e1.shape[1],out_channels= 25,kernel_size = 1)(e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5da08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled1 = [a1,b1,c1,d1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6be343",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"e1 = {e1.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ded3885",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f1.shape)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:nn3]",
   "language": "python",
   "name": "conda-env-nn3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "135px",
    "width": "160px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "neural network",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 337.852,
   "position": {
    "height": "359.852px",
    "left": "725px",
    "right": "20px",
    "top": "109px",
    "width": "544px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
